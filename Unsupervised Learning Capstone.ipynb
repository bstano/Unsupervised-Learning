{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Author From Text\n",
    "\n",
    "I want to make a model that can predict who has written a story based on its text features.  To accomplish this, I will use data from the NLTK 'Gutenberg' corpus. (add data set decription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import genesis\n",
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning / processing / language parsing\n",
    "\n",
    "I need to make sure my data is clean and workable when I make my features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Persuasion by Jane Austen\n",
    "persuasion_raw = gutenberg.raw('austen-persuasion.txt')\n",
    "\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion_raw)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean The Poems of William Blake\n",
    "blake_raw = gutenberg.raw('blake-poems.txt')\n",
    "\n",
    "blake = re.sub(r'[A-Z][^a-z]*[A-Z]\\s','', blake_raw)\n",
    "blake = re.sub(r'\\n[a-z][a-z ]*\\n','', blake)\n",
    "blake = text_cleaner(blake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean some of the short stories of William Cullen Bryant\n",
    "bryant_raw = gutenberg.raw('bryant-stories.txt')\n",
    "\n",
    "bryant = re.sub(r'[A-Z][^a-z]+[A-Z][A-Z]','', bryant_raw)\n",
    "bryant = text_cleaner(bryant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean The Adventures of Buster Bear by Thornton Burgess\n",
    "buster_raw = gutenberg.raw('burgess-busterbrown.txt')\n",
    "\n",
    "buster = re.sub(r'[A-Z][^a-z]+[A-Z][A-Z]','', buster_raw)\n",
    "buster = text_cleaner(buster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Alice in Wonderland by Lewis Carroll\n",
    "alice_raw = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "alice = re.sub(r'CHAPTER [A-Z]*.','', alice_raw)\n",
    "alice = text_cleaner(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean The Man Who Became Thursday by G. K. Chesterton\n",
    "thursday_raw = gutenberg.raw('chesterton-thursday.txt')\n",
    "\n",
    "thursday = re.sub(r'[A-Z][^a-z]+[A-Z][A-Z]','', thursday_raw)\n",
    "thursday = text_cleaner(thursday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean The Parent's Assistent by Richard Lovell Edgeworth\n",
    "parents_raw = gutenberg.raw('edgeworth-parents.txt')\n",
    "\n",
    "parents = re.sub(r'[A-Z][^a-z]+[A-Z][A-Z]\\W','', parents_raw)\n",
    "parents = text_cleaner(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Moby Dick by Herman Melville\n",
    "moby_raw = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "#remove etomology and the extracts\n",
    "moby_no_et = 'Call me Ishmael.' + moby_raw.split('Call me Ishmael.')[1]\n",
    "\n",
    "moby = re.sub(r'CHAPTER\\s*\\d.\\s*[\\w\\s\\-]+\\.','', moby_no_et)\n",
    "moby= text_cleaner(moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Hamlet by William Shakespeare\n",
    "hamlet_raw = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "hamlet = re.sub(r'Actus [A-Z][a-z]*\\.','', hamlet_raw) # Remove act numbers\n",
    "hamlet = re.sub(r'Scoena [A-Z][a-z]*\\.','', hamlet) # Remove scene numbers\n",
    "hamlet = re.sub(r'\\n\\s*[A-Z][a-z]*\\.','', hamlet) # Remove charactr's names before their lines\n",
    "hamlet = re.sub(r'\\n\\n\\s*[A-Z][a-z]*\\.','', hamlet) # Remove charactr's names before their lines\n",
    "hamlet = text_cleaner(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Leaves of Grass by Walt Whitman\n",
    "leaves_raw = gutenberg.raw('whitman-leaves.txt')\n",
    "\n",
    "leaves = re.sub(r'\\s\\s\\d\\n','', leaves_raw) # Remove line Numberings\n",
    "leaves = re.sub(r'\\}  [A-Z][\\w\\s\\\\\\'\\-\\\"\\,\\?\\!]*[a-z\\?\\!]\\n\\n','', leaves_raw) # Remove Peom Titles\n",
    "leaves = re.sub(r'Walt Whitman','', leaves_raw) # Remove anytime Walt Whitman signed his name\n",
    "leaves = re.sub(r'Whitman','', leaves_raw) # Remove anytime Walt Whitman signed his name\n",
    "\n",
    "leaves = text_cleaner(leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of each text, to prevent memory errors\n",
    "persuasiontr = persuasion[:30000]\n",
    "blaketr = blake[:30000]\n",
    "bryanttr = bryant[:30000]\n",
    "bustertr = buster[:30000]\n",
    "alicetr = alice[:30000]\n",
    "thursdaytr = thursday[:30000]\n",
    "parentstr = parents[:30000]\n",
    "mobytr = moby[:30000]\n",
    "hamlettr = hamlet[:30000]\n",
    "leavestr = leaves[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692262"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features\n",
    "\n",
    "I must extract features from the text, through a process called NLP, Natural Language Processing. Though there are many ways to accomplish this, I will use 2: Bag of Words and Term-Frequency with Inverse Document Frequency, or TF IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion_doc = nlp(persuasiontr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blake_doc = nlp(blaketr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bryant_doc = nlp(bryanttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "buster_doc = nlp(bustertr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_doc = nlp(alicetr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thursday_doc = nlp(thursdaytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_doc = nlp(parentstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_doc = nlp(mobytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_doc = nlp(hamlettr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_doc = nlp(leavestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "blake_sents = [[sent, \"Blake\"] for sent in blake_doc.sents]\n",
    "bryant_sents = [[sent, \"Bryant\"] for sent in bryant_doc.sents]\n",
    "buster_sents = [[sent, \"Burgess\"] for sent in buster_doc.sents]\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "thursday_sents = [[sent, \"Chesterton\"] for sent in thursday_doc.sents]\n",
    "parents_sents = [[sent, \"Edgeworth\"] for sent in parents_doc.sents]\n",
    "moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "hamlet_sents = [[sent, \"Shakespeare\"] for sent in hamlet_doc.sents]\n",
    "leaves_sents = [[sent, \"Whitman\"] for sent in leaves_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_list = [persuasion_sents, bryant_sents, buster_sents, alice_sents, thursday_sents, \n",
    "            parents_sents, moby_sents, blake_sents, hamlet_sents, leaves_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last sentence due to initial cutoff\n",
    "for sent in sents_list:\n",
    "    l = len(sent)\n",
    "    del sent[l-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_grouped = [item for sublist in sents_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Sir, Walter, Elliot, ,, of, Kellynch, Hall, ,...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(This, was, the, page, at, which, the, favouri...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Walter, Elliot, ,, born, March, 1, ,, 1760, ,...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(of, South, Park, ,, in, the, county, of, Glou...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\", Precisely, such, had, the, paragraph, orig...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0  (Sir, Walter, Elliot, ,, of, Kellynch, Hall, ,...  Austen\n",
       "1  (This, was, the, page, at, which, the, favouri...  Austen\n",
       "2  (Walter, Elliot, ,, born, March, 1, ,, 1760, ,...  Austen\n",
       "3  (of, South, Park, ,, in, the, county, of, Glou...  Austen\n",
       "4  (\", Precisely, such, had, the, paragraph, orig...  Austen"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame(sents_grouped)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "I will use the bag of words technique first. To use this, I will need to process the texts down to sentences. From there, I will extract information on each sentences verbosity and punctuation use. I will use this information to characterize each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_author'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df['punctuation'] = 0\n",
    "    df['other punctuation'] = 0\n",
    "    df.loc[:, '.'] = 0\n",
    "    df.loc[:, '?'] = 0\n",
    "    df.loc[:, '!'] = 0\n",
    "    df.loc[:, ','] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation, stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # Get number of punctuation in a sentence\n",
    "        puncs = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     token.is_punct\n",
    "                 )]\n",
    "        # Increase punctuation count by how many were use\n",
    "        for punc in puncs:\n",
    "            df.loc[i,'punctuation'] += 1\n",
    "            try:\n",
    "                df.loc[i,punc] += 1\n",
    "            except:\n",
    "                df.loc[i,'other punctuation'] += 1\n",
    "                \n",
    "            \n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 200 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "blakewords = bag_of_words(blake_doc)\n",
    "bryantwords = bag_of_words(bryant_doc)\n",
    "busterwords = bag_of_words(buster_doc)\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "thursdaywords = bag_of_words(thursday_doc)\n",
    "parentswords = bag_of_words(parents_doc)\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "hamletwords = bag_of_words(hamlet_doc)\n",
    "leaveswords = bag_of_words(leaves_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(persuasionwords + bryantwords + busterwords + alicewords + thursdaywords + \n",
    "                   parentswords + mobywords + blakewords + hamletwords + leaveswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "persuasion_sents = pd.DataFrame(persuasion_sents)\n",
    "# Get BOW features\n",
    "persuasion_word_counts = bow_features(persuasion_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "blake_sents = pd.DataFrame(blake_sents)\n",
    "# Get BOW features\n",
    "blake_word_counts = bow_features(blake_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "bryant_sents = pd.DataFrame(bryant_sents)\n",
    "# Get BOW features\n",
    "bryant_word_counts = bow_features(bryant_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "buster_sents = pd.DataFrame(buster_sents)\n",
    "# Get BOW features\n",
    "buster_word_counts = bow_features(buster_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "alice_sents = pd.DataFrame(alice_sents)\n",
    "# Get BOW features\n",
    "alice_word_counts = bow_features(alice_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "thursday_sents = pd.DataFrame(thursday_sents)\n",
    "# Get BOW features\n",
    "thursday_word_counts = bow_features(thursday_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "parents_sents = pd.DataFrame(parents_sents)\n",
    "# Get BOW features\n",
    "parents_word_counts = bow_features(parents_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "moby_sents = pd.DataFrame(moby_sents)\n",
    "# Get BOW features\n",
    "moby_word_counts = bow_features(moby_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n",
      "Processing row 400\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "hamlet_sents = pd.DataFrame(hamlet_sents)\n",
    "# Get BOW features\n",
    "hamlet_word_counts = bow_features(hamlet_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "# Convert to data frame for the BOW\n",
    "leaves_sents = pd.DataFrame(leaves_sents)\n",
    "# Get BOW features\n",
    "leaves_word_counts = bow_features(leaves_sents, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_counts = pd.concat([persuasion_word_counts,alice_word_counts,thursday_word_counts,\n",
    "                               parents_word_counts,moby_word_counts,blake_word_counts,hamlet_word_counts,leaves_word_counts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion = gutenberg.paras('austen-persuasion.txt')\n",
    "#processing\n",
    "persuasion_paras=[]\n",
    "for paragraph in persuasion:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    persuasion_paras.append(' '.join(para))\n",
    "    \n",
    "persuasion_len = len(persuasion_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "blake = gutenberg.paras('blake-poems.txt')\n",
    "#processing\n",
    "blake_paras=[]\n",
    "for paragraph in blake:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    blake_paras.append(' '.join(para))\n",
    "    \n",
    "blake_len = len(blake_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bryant = gutenberg.paras('bryant-stories.txt')\n",
    "#processing\n",
    "bryant_paras=[]\n",
    "for paragraph in bryant:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    bryant_paras.append(' '.join(para))\n",
    "    \n",
    "bryant_len = len(bryant_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "buster = gutenberg.paras('burgess-busterbrown.txt')\n",
    "#processing\n",
    "buster_paras=[]\n",
    "for paragraph in buster:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    buster_paras.append(' '.join(para))\n",
    "    \n",
    "buster_len = len(buster_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = gutenberg.paras('carroll-alice.txt')\n",
    "#processing\n",
    "alice_paras=[]\n",
    "for paragraph in alice:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    alice_paras.append(' '.join(para))\n",
    "    \n",
    "alice_len = len(alice_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "thursday = gutenberg.paras('chesterton-thursday.txt')\n",
    "#processing\n",
    "thursday_paras=[]\n",
    "for paragraph in thursday:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    thursday_paras.append(' '.join(para))\n",
    "    \n",
    "thursday_len = len(thursday_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = gutenberg.paras('edgeworth-parents.txt')\n",
    "#processing\n",
    "parents_paras=[]\n",
    "for paragraph in parents:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    parents_paras.append(' '.join(para))\n",
    "    \n",
    "parents_len = len(parents_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = gutenberg.paras('melville-moby_dick.txt')\n",
    "#processing\n",
    "moby_paras=[]\n",
    "for paragraph in moby:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    moby_paras.append(' '.join(para))\n",
    "    \n",
    "moby_len = len(moby_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = gutenberg.paras('shakespeare-hamlet.txt')\n",
    "caesar = gutenberg.paras('shakespeare-caesar.txt')\n",
    "macbeth = gutenberg.paras('shakespeare-macbeth.txt')\n",
    "\n",
    "#processing\n",
    "shake_paras=[]\n",
    "for paragraph in hamlet:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    shake_paras.append(' '.join(para))\n",
    "    \n",
    "for paragraph in caesar:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    shake_paras.append(' '.join(para))\n",
    "    \n",
    "for paragraph in macbeth:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    shake_paras.append(' '.join(para))\n",
    "    \n",
    "shake_len = len(shake_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = gutenberg.paras('whitman-leaves.txt')\n",
    "#processing\n",
    "leaves_paras=[]\n",
    "for paragraph in leaves:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    leaves_paras.append(' '.join(para))\n",
    "    \n",
    "leaves_len = len(leaves_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paras = persuasion_paras + blake_paras + bryant_paras + buster_paras + alice_paras + thursday_paras + parents_paras + moby_paras + shake_paras + leaves_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(persuasion_len):\n",
    "    labels.append('Austen')\n",
    "for i in range(blake_len):\n",
    "    labels.append('Blake')\n",
    "for i in range(bryant_len):\n",
    "    labels.append('Bryant')\n",
    "for i in range(buster_len):\n",
    "    labels.append('Burgess')\n",
    "for i in range(alice_len):\n",
    "    labels.append('Carroll')\n",
    "for i in range(thursday_len):\n",
    "    labels.append('Chesterton')\n",
    "for i in range(parents_len):\n",
    "    labels.append('Edgeworth')\n",
    "for i in range(moby_len):\n",
    "    labels.append('Melville')\n",
    "for i in range(shake_len):\n",
    "    labels.append('Shakespeare')\n",
    "for i in range(leaves_len):\n",
    "    labels.append('Whitman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10703\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "all_paras_tfidf=vectorizer.fit_transform(all_paras)\n",
    "print(\"Number of features: %d\" % all_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf, Y_train, Y_test = train_test_split(all_paras_tfidf, labels, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "X_test_tfidf_csr = X_test_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-62-c135d957f48e>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-c135d957f48e>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    (add code to show what the features are)\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130\n",
    "svd= TruncatedSVD(500)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "(add code to show what the features are)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Clusters\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km0 = KMeans(n_clusters=10, random_state=0)\n",
    "y_pred0 = km0.fit_predict(X_train_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km1 = KMeans(n_clusters=10, random_state=7)\n",
    "y_pred1 = km1.fit_predict(X_train_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters=10, random_state=42)\n",
    "y_pred2 = km2.fit_predict(X_train_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km3 = KMeans(n_clusters=10, random_state=121)\n",
    "y_pred3 = km3.fit_predict(X_train_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km4 = KMeans(n_clusters=10, random_state=1337)\n",
    "y_pred4 = km4.fit_predict(X_train_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 0 Inertia: ',km0.inertia_)\n",
    "print('\\nComparing the K-Means 0 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_train,y_pred0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 1 Inertia: ',km1.inertia_)\n",
    "print('\\nComparing the K-Means 1 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_train,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 2 Inertia: ',km2.inertia_)\n",
    "print('\\nComparing the K-Means 2 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_train,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 3 Inertia: ',km3.inertia_)\n",
    "print('\\nComparing the K-Means 3 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_train,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 4 Inertia: ',km4.inertia_)\n",
    "print('\\nComparing the K-Means 4 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_train,y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Author Using Various Models and Feature Sets\n",
    "\n",
    "I will now test my ability to predict author from text. There are many different types of models with many different usesm but I will try 4 different ones here: Logistic Regression, Random Forest, Grandient-Boosted Decision Trees, and Support Vector Classifier. \n",
    "\n",
    "Additionally, I will be modeling with both of my features sets.\n",
    "\n",
    "I will check each models cross validation score to check the overall health of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Feature Set\n",
    "X_bow = total_word_counts.drop(['text_author','text_sentence'],1)\n",
    "y_bow = total_word_counts.text_author\n",
    "Xtrain_bow, Xtest_bow, ytrain_bow, ytest_bow = train_test_split(X_bow,y_bow,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = [.01,.1,1,5,7,8,9,10,11,12,15,20,30,50,70,100,150,200]\n",
    "bestc = 0\n",
    "bestscore = 0\n",
    "for c in constants:\n",
    "    lr_bow = LogisticRegression(C=c,random_state=42)\n",
    "    lr_bow.fit(Xtrain_bow, ytrain_bow)\n",
    "    score = lr_bow.score(Xtest_bow, ytest_bow)\n",
    "    if score > bestscore:\n",
    "        bestc = c\n",
    "        bestscore = score\n",
    "        print('Best C value is ',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow = LogisticRegression(C=bestc,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow.fit(Xtrain_bow, ytrain_bow)\n",
    "print('Training set score:', lr_bow.score(Xtrain_bow, ytrain_bow))\n",
    "print('\\nTest set score:', lr_bow.score(Xtest_bow, ytest_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bow_cv = cross_val_score(lr_bow, Xtest_bow, ytest_bow, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression Cross Validation\\n')\n",
    "display(lr_bow_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(lr_bow_cv.mean(),3),' +/- ',round(lr_bow_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = [.01,.1,1,10,100,200,300,400,500,700,1000]\n",
    "bestc = 0\n",
    "bestscore = 0\n",
    "for c in constants:\n",
    "    lr_lsa = LogisticRegression(C=c,random_state=42)\n",
    "    lr_lsa.fit(X_train_lsa, Y_train)\n",
    "    score = lr_lsa.score(X_test_lsa, Y_test)\n",
    "    if score > bestscore:\n",
    "        bestc = c\n",
    "        bestscore = score\n",
    "        print('Best C value is ',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lsa = LogisticRegression(C=bestc,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lsa.fit(X_train_lsa, Y_train)\n",
    "print('Training set score:', lr_lsa.score(X_train_lsa, Y_train))\n",
    "print('\\nTest set score:', lr_lsa.score(X_test_lsa, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lsa_cv = cross_val_score(lr_lsa, X_test_lsa, Y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression Cross Validation\\n')\n",
    "display(lr_lsa_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(lr_lsa_cv.mean(),3),' +/- ',round(lr_lsa_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bow = GradientBoostingClassifier(n_estimators=50,max_depth=2,random_state=42)\n",
    "clf_bow.fit(Xtrain_bow, ytrain_bow)\n",
    "print('Training set score:', clf_bow.score(Xtrain_bow, ytrain_bow))\n",
    "print('\\nTest set score:', clf_bow.score(Xtest_bow, ytest_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bow_cv = cross_val_score(clf_bow, Xtest_bow, ytest_bow, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient-Boosted Tree Cross Validation\\n')\n",
    "display(clf_bow_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(clf_bow_cv.mean(),3),' +/- ',round(clf_bow_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lsa = GradientBoostingClassifier(n_estimators=50,max_depth=2,random_state=42)\n",
    "clf_lsa.fit(X_train_lsa, Y_train)\n",
    "print('Training set score:', clf_lsa.score(X_train_lsa, Y_train))\n",
    "print('\\nTest set score:', clf_lsa.score(X_test_lsa, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lsa_cv = cross_val_score(clf_lsa, X_test_lsa, Y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient-Boosted Tree Cross Validation\\n')\n",
    "display(clf_lsa_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(clf_lsa_cv.mean(),3),' +/- ',round(clf_lsa_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_bow = RandomForestClassifier(n_estimators=50,random_state=42)\n",
    "rfc_bow.fit(Xtrain_bow, ytrain_bow)\n",
    "print('Training set score:', rfc_bow.score(Xtrain_bow, ytrain_bow))\n",
    "print('\\nTest set score:', rfc_bow.score(Xtest_bow, ytest_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_bow_cv = cross_val_score(rfc_bow, Xtest_bow, ytest_bow, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Cross Validation\\n')\n",
    "display(rfc_bow_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(rfc_bow_cv.mean(),3),' +/- ',round(rfc_bow_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_lsa = RandomForestClassifier(n_estimators=50,random_state=42)\n",
    "rfc_lsa.fit(X_train_lsa, Y_train)\n",
    "print('Training set score:', rfc_lsa.score(X_train_lsa, Y_train))\n",
    "print('\\nTest set score:', rfc_lsa.score(X_test_lsa, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_lsa_cv = cross_val_score(rfc_lsa, X_test_lsa, Y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Random Forest Cross Validation\\n')\n",
    "display(rfc_lsa_cv)\n",
    "print('\\nMean and Standard Error:')\n",
    "print(round(rfc_lsa_cv.mean(),3),' +/- ',round(rfc_lsa_cv.std()*2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Conclusion\n",
    "\n",
    "The best model to model the BOW feature set was Logistic Regression, having the highest accuracy score and a fairly stable cross valiadation score.\n",
    "\n",
    "The best model to predict with the TF IDF feature set was the Random Forest Classifier. \n",
    "\n",
    "Though Logistic Regression using BOW Features had the best testing score, the Random Forest using the TF IDF features showed a more stable cross validation score. Because of that, I will treat both of them as the most effective and try to improve on each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Holdout Group\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmt0 = KMeans(n_clusters=10, random_state=0)\n",
    "y_predt0 = kmt0.fit_predict(X_test_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmt1 = KMeans(n_clusters=10, random_state=7)\n",
    "y_predt1 = kmt1.fit_predict(X_test_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmt2 = KMeans(n_clusters=10, random_state=42)\n",
    "y_predt2 = kmt2.fit_predict(X_test_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmt3 = KMeans(n_clusters=10, random_state=121)\n",
    "y_predt3 = kmt3.fit_predict(X_test_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmt4 = KMeans(n_clusters=10, random_state=1337)\n",
    "y_predt4 = kmt4.fit_predict(X_test_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 0 Inertia: ',km0.inertia_)\n",
    "print('\\nComparing the K-Means 0 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_test,y_predt0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 1 Inertia: ',km1.inertia_)\n",
    "print('\\nComparing the K-Means 1 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_test,y_predt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 2 Inertia: ',km2.inertia_)\n",
    "print('\\nComparing the K-Means 2 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_test,y_predt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 3 Inertia: ',km3.inertia_)\n",
    "print('\\nComparing the K-Means 3 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_test,y_predt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KMeans 4 Inertia: ',km4.inertia_)\n",
    "print('\\nComparing the K-Means 4 clusters to the actual author groupings:\\n')\n",
    "print(pd.crosstab(Y_test,y_predt4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Clusters Conclusion\n",
    "\n",
    "Find real meaning of what the clusters are grouping upon. poke around and see what the each is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
