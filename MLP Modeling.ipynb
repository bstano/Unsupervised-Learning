{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Neural Network Modeling\n",
    "\n",
    "I want to display the value of MLP neural network modeling. \n",
    "\n",
    "The data I will model is of all possible poker hands.  The value of each card is represented by a value representing its suit, and a value representing its numeric (or royal) value, totaling to 10 features in total. The last column is the outcome variable, the type of hand a person has (single card high, pair, full house, etc.).  This is represented as a number from 0-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import timeit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from  sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data\n",
    "\n",
    "I am taking my data set from the UCI machine learning data base. \n",
    "\n",
    "The train and test set have already been split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data')\n",
    "test = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (25009, 11)\n",
      "Test data shape:  (999999, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape: ',train.shape)\n",
    "print('Test data shape: ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>1.1</th>\n",
       "      <th>11</th>\n",
       "      <th>1.2</th>\n",
       "      <th>13</th>\n",
       "      <th>1.3</th>\n",
       "      <th>12</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  10  1.1  11  1.2  13  1.3  12  1.4  1.5  9\n",
       "0  2  11    2  13    2  10    2  12    2    1  9\n",
       "1  3  12    3  11    3  13    3  10    3    1  9\n",
       "2  4  10    4  11    4   1    4  13    4   12  9\n",
       "3  4   1    4  13    4  12    4  11    4   10  9\n",
       "4  1   2    1   4    1   5    1   3    1    6  8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has not come with column names and the first row of data has been erroneuosly forced to the column names. I will need to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_columns = ['Suit1','Rank1','Suit2','Rank2','Suit3','Rank3','Suit4','Rank4','Suit5','Rank5','Hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "misplaced = pd.Series(train.columns,index=true_columns)\n",
    "misplaced = misplaced.astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = true_columns\n",
    "train = train.append(misplaced,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suit1</th>\n",
       "      <th>Rank1</th>\n",
       "      <th>Suit2</th>\n",
       "      <th>Rank2</th>\n",
       "      <th>Suit3</th>\n",
       "      <th>Rank3</th>\n",
       "      <th>Suit4</th>\n",
       "      <th>Rank4</th>\n",
       "      <th>Suit5</th>\n",
       "      <th>Rank5</th>\n",
       "      <th>Hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Suit1  Rank1  Suit2  Rank2  Suit3  Rank3  Suit4  Rank4  Suit5  Rank5  Hand\n",
       "0      2     11      2     13      2     10      2     12      2      1     9\n",
       "1      3     12      3     11      3     13      3     10      3      1     9\n",
       "2      4     10      4     11      4      1      4     13      4     12     9\n",
       "3      4      1      4     13      4     12      4     11      4     10     9\n",
       "4      1      2      1      4      1      5      1      3      1      6     8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = true_columns\n",
    "test = test.append(misplaced,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suit1</th>\n",
       "      <th>Rank1</th>\n",
       "      <th>Suit2</th>\n",
       "      <th>Rank2</th>\n",
       "      <th>Suit3</th>\n",
       "      <th>Rank3</th>\n",
       "      <th>Suit4</th>\n",
       "      <th>Rank4</th>\n",
       "      <th>Suit5</th>\n",
       "      <th>Rank5</th>\n",
       "      <th>Hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Suit1  Rank1  Suit2  Rank2  Suit3  Rank3  Suit4  Rank4  Suit5  Rank5  Hand\n",
       "0      3     12      3      2      3     11      4      5      2      5     1\n",
       "1      1      9      4      6      1      4      3      2      3      9     1\n",
       "2      1      4      3     13      2     13      2      1      3      6     1\n",
       "3      3     10      2      7      1      2      2     11      4      9     0\n",
       "4      1      3      4      5      3      4      1     12      4      6     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.499520\n",
       "1    0.423790\n",
       "2    0.048221\n",
       "3    0.020512\n",
       "4    0.003719\n",
       "5    0.002159\n",
       "6    0.001439\n",
       "7    0.000240\n",
       "9    0.000200\n",
       "8    0.000200\n",
       "Name: Hand, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Hand.value_counts()/len(train.Hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the outcome is inbalanced in the training data, I do not think I should balance it, due to the nature of this data.  Since the training data represents literally all possible combinations of poker hands and I do not have the processing power to model on a data set much larger than the training data, I would have to downsample, leading to loss of information.  \n",
    "\n",
    "For curiousity sake, I will resample the data to balance the outcome and show it is not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for target in range(9):\n",
    "    outcome = train[train.Hand==target]\n",
    "    sampled = resample(outcome,replace=True,n_samples=3000,random_state=42)\n",
    "    x.append(sampled)\n",
    "\n",
    "train_sampled = pd.concat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsize the test set, as it is much too big work with\n",
    "leftover, test_sampled = train_test_split(test,test_size=50000,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "I would model primarily with the Multi-Layer Perceptron Classifier, MLPC. I will try it in 4 different configurations, including one to test the balanced outcome training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train.drop('Hand',1)\n",
    "Ytrain = train.Hand\n",
    "\n",
    "Xsamp = train_sampled.drop('Hand',1)\n",
    "Ysamp = train_sampled.Hand\n",
    "\n",
    "Xtest = test_sampled.drop('Hand',1)\n",
    "Ytest = test_sampled.Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50474\n",
       "1    0.42010\n",
       "2    0.04614\n",
       "3    0.02126\n",
       "4    0.00406\n",
       "5    0.00194\n",
       "6    0.00144\n",
       "7    0.00032\n",
       "Name: Hand, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest.value_counts()/len(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Config 1\n",
    "\n",
    "This configuration will be rather basic, using a single layer neural network 100 nodes wide. It will have an alpha value of 0.5, Which will be standard across all the MLP configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  7.378  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(100,),random_state=42,alpha=0.5)\n",
    "mlp1.fit(Xtrain, Ytrain)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtime1 = stop - start\n",
    "print('Runtime: ',round(runtime1,3),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.6143942423030788\n",
      "Testing Score:  0.603\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',mlp1.score(Xtrain, Ytrain))\n",
    "print('Testing Score: ',mlp1.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64484206, 0.66550035, 0.58385839, 0.58607582, 0.62088627])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp1, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Config  2\n",
    "\n",
    "This configuration is identical to the previous one, but it uses the sampled training data with a balanced outcome set, but at the cost of a huge information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  18.12  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100,),random_state=42,alpha=0.5)\n",
    "mlp2.fit(Xsamp, Ysamp)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtime2 = stop - start\n",
    "print('Runtime: ',round(runtime2,3),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.7395555555555555\n",
      "Testing Score:  0.36692\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',mlp2.score(Xsamp, Ysamp))\n",
    "print('Testing Score: ',mlp2.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64484206, 0.66550035, 0.58385839, 0.58607582, 0.62088627])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp2, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Config 3\n",
    "\n",
    "This configuration differents from the first one by adding 2 addition hidden layers, both 10 nodes wide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  12.467  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(100,10,10,),random_state=42,alpha=0.5)\n",
    "mlp3.fit(Xtrain, Ytrain)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtime3 = stop - start\n",
    "print('Runtime: ',round(runtime3,3),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.6716913234706118\n",
      "Testing Score:  0.65668\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',mlp3.score(Xtrain, Ytrain))\n",
    "print('Testing Score: ',mlp3.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94402239, 0.88813356, 0.6029603 , 0.77353206, 0.7463239 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp3, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 4\n",
    "\n",
    "This configuration is very different to the previous ones, having an initial layer 50 nodes wides and 4 additional hidden layers all 10 nodes wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  13.955  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(50,10,10,10,10,),random_state=42,alpha=0.5)\n",
    "mlp4.fit(Xtrain, Ytrain)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtime4 = stop - start\n",
    "print('Runtime: ',round(runtime4,3),' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha=0.5, 7.408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.6207117153138745\n",
      "Testing Score:  0.61088\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',mlp4.score(Xtrain, Ytrain))\n",
    "print('Testing Score: ',mlp4.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha=0.5\n",
    "Training Score:  0.4995201919232307\n",
    "Testing Score:  0.4955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68502599, 0.66280116, 0.5759576 , 0.64709413, 0.63979194])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp4, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Conclusion\n",
    "\n",
    "The single-layer MLP performed decently well, having a decent runtime, and accuracy, and cross-validation score, its cv score only having 1 slight inconsistency.\n",
    "\n",
    "As expected, the MLP using the sampled data was disasterous. Though it trained much better than the unbalanced training set, it tested horribly, having the worst accuracy by far. Because this data was not a sample, but in fact a complete representation of all possible combinations, trying to balance the classes caused too much information loss. If I had more computing power, I would try to upsample the smaller classes, only increasing the training size.\n",
    "\n",
    "The MLP with 2 addition 10 node layers performed better than the initial configuration in terms of accuracy, but had a more less inconsistent cross validation score. Even though it has double the runtime, its more than 5% increase in test score and steller cross-validation score is more than worth it.\n",
    "\n",
    "The MLP with and 50 node first layer and 4 addition 10 node hidden layers performed slightly better than the initial configuration in terms of accuracy, but had a much less inconsistent cross-validation score.\n",
    "\n",
    "The best model configuration to use is the initial one, a single, 100-node-wide layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLP Against Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  6.634  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "rfc.fit(Xtrain,Ytrain)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtimerfc = stop - start\n",
    "print('Runtime: ',round(runtimerfc,3),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  1.0\n",
      "Testing Score:  0.61876\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',rfc.score(Xtrain, Ytrain))\n",
    "print('Testing Score: ',rfc.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64114354, 0.63630911, 0.65066507, 0.63349005, 0.6449935 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  23.396  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(Xtrain,Ytrain)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "runtimegbc = stop - start\n",
    "print('Runtime: ',round(runtimegbc,3),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.6287085165933627\n",
      "Testing Score:  0.61468\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',gbc.score(Xtrain, Ytrain))\n",
    "print('Testing Score: ',gbc.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60845662, 0.60491852, 0.61116112, 0.60098029, 0.59147744])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gbc, Xtest, Ytest, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Model Conclusion\n",
    "\n",
    "The  RFC model seemed to overfit the data, having a perfect training score and a much lower testing score. Still, it cross validated well, so that may not be the case. It still tested better than the best MLP\n",
    "\n",
    "The GBC model performed very well, having good traing, testing, and cross-validation scores. This is the best performing model of poker data overall. \n",
    "\n",
    "Both the RFC and the GBC models performed better than the most stable configuration of MLPC, both having higher traing and testing accuracy as well as much better cross-validation scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
