{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timeit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks = pd.read_csv('https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Columns.\n",
    "artworks = artworks[['Artist', 'Nationality', 'Gender', 'Date', 'Department',\n",
    "                    'DateAcquired', 'URL', 'ThumbnailURL', 'Height (cm)', 'Width (cm)']]\n",
    "\n",
    "# Convert URL's to booleans.\n",
    "artworks['URL'] = artworks['URL'].notnull()\n",
    "artworks['ThumbnailURL'] = artworks['ThumbnailURL'].notnull()\n",
    "\n",
    "# Drop films and some other tricky rows.\n",
    "artworks = artworks[artworks['Department']!='Film']\n",
    "artworks = artworks[artworks['Department']!='Media and Performance Art']\n",
    "artworks = artworks[artworks['Department']!='Fluxus Collection']\n",
    "\n",
    "#remove these for the sake of computational efficiency\n",
    "artworks = artworks[artworks['Department']!='Architecture & Design']\n",
    "artworks = artworks[artworks['Department']!='Drawings']\n",
    "artworks = artworks[artworks['Department']!='Painting & Sculpture']\n",
    "\n",
    "# Drop missing data.\n",
    "artworks = artworks.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79297, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>DateAcquired</th>\n",
       "      <th>URL</th>\n",
       "      <th>ThumbnailURL</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>K. P. Brehmer</td>\n",
       "      <td>(German)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1971</td>\n",
       "      <td>Prints &amp; Illustrated Books</td>\n",
       "      <td>1973-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>Various Artists, Wolf Vostell, Sigmar Polke, K...</td>\n",
       "      <td>(Various) (German) (German) (German) (German) ...</td>\n",
       "      <td>() (Male) (Male) (Male) (Male) (Male) (Male)</td>\n",
       "      <td>1971</td>\n",
       "      <td>Prints &amp; Illustrated Books</td>\n",
       "      <td>1973-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>K. H. Hödicke</td>\n",
       "      <td>(German)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1971</td>\n",
       "      <td>Prints &amp; Illustrated Books</td>\n",
       "      <td>1973-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>Konrad Lueg</td>\n",
       "      <td>(German)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1971</td>\n",
       "      <td>Prints &amp; Illustrated Books</td>\n",
       "      <td>1973-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>Unknown Artist</td>\n",
       "      <td>(Nationality Unknown)</td>\n",
       "      <td>()</td>\n",
       "      <td>c. 1920</td>\n",
       "      <td>Prints &amp; Illustrated Books</td>\n",
       "      <td>2001-01-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>18.7</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Artist  \\\n",
       "7955                                      K. P. Brehmer   \n",
       "7956  Various Artists, Wolf Vostell, Sigmar Polke, K...   \n",
       "7957                                      K. H. Hödicke   \n",
       "7958                                        Konrad Lueg   \n",
       "7959                                     Unknown Artist   \n",
       "\n",
       "                                            Nationality  \\\n",
       "7955                                           (German)   \n",
       "7956  (Various) (German) (German) (German) (German) ...   \n",
       "7957                                           (German)   \n",
       "7958                                           (German)   \n",
       "7959                              (Nationality Unknown)   \n",
       "\n",
       "                                            Gender     Date  \\\n",
       "7955                                        (Male)     1971   \n",
       "7956  () (Male) (Male) (Male) (Male) (Male) (Male)     1971   \n",
       "7957                                        (Male)     1971   \n",
       "7958                                        (Male)     1971   \n",
       "7959                                            ()  c. 1920   \n",
       "\n",
       "                      Department DateAcquired   URL  ThumbnailURL  \\\n",
       "7955  Prints & Illustrated Books   1973-01-04  True          True   \n",
       "7956  Prints & Illustrated Books   1973-01-04  True          True   \n",
       "7957  Prints & Illustrated Books   1973-01-04  True          True   \n",
       "7958  Prints & Illustrated Books   1973-01-04  True          True   \n",
       "7959  Prints & Illustrated Books   2001-01-24  True          True   \n",
       "\n",
       "      Height (cm)  Width (cm)  \n",
       "7955         14.9        16.6  \n",
       "7956         20.8        24.0  \n",
       "7957         10.8         8.1  \n",
       "7958          2.6         2.0  \n",
       "7959         18.7        44.8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(artworks.shape)\n",
    "artworks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist           object\n",
       "Nationality      object\n",
       "Gender           object\n",
       "Date             object\n",
       "Department       object\n",
       "DateAcquired     object\n",
       "URL                bool\n",
       "ThumbnailURL       bool\n",
       "Height (cm)     float64\n",
       "Width (cm)      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data types.\n",
    "artworks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks['DateAcquired'] = pd.to_datetime(artworks.DateAcquired)\n",
    "artworks['YearAcquired'] = artworks.DateAcquired.dt.year\n",
    "artworks['YearAcquired'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple nationalities, genders, and artists.\n",
    "artworks.loc[artworks['Gender'].str.contains('\\) \\('), 'Gender'] = '\\(multiple_persons\\)'\n",
    "artworks.loc[artworks['Nationality'].str.contains('\\) \\('), 'Nationality'] = '\\(multiple_nationalities\\)'\n",
    "artworks.loc[artworks['Artist'].str.contains(','), 'Artist'] = 'Multiple_Artists'\n",
    "\n",
    "# Convert dates to start date, cutting down number of distinct examples.\n",
    "artworks['Date'] = pd.Series(artworks.Date.str.extract(\n",
    "    '([0-9]{4})', expand=False))[:-1]\n",
    "\n",
    "# Final column drops and NA drop.\n",
    "X = artworks.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "artists = pd.get_dummies(artworks.Artist)\n",
    "nationalities = pd.get_dummies(artworks.Nationality)\n",
    "dates = pd.get_dummies(artworks.Date)\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X = pd.concat([X, nationalities, dates], axis=1)\n",
    "\n",
    "Y = artworks.Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, Xz, Yt, Yz = train_test_split(X,Y, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 1: 1 Layer, 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  8.933158241767842\n"
     ]
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(1000,),random_state=42)\n",
    "mlp1.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime1 = stop - start\n",
    "print('Runtime: ',runtime1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6102143757881463"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68978562, 0.75598991, 0.75094578, 0.70554855, 0.73266078])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp1, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 2: 1 Layer, 1000 with alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  7.140291721827225\n"
     ]
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(1000,),alpha=0.5,random_state=42)\n",
    "mlp2.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime2 = stop - start\n",
    "print('Runtime: ',runtime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915510718789407"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73896595, 0.31525851, 0.6998739 , 0.71941992, 0.70996217])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp2, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing alpha decreases runtime and increases performance. Of course, this is only for this particular data, as the alpha coefficient reduces the size of very large parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 3: 1 Layer, 1000 with activation = logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  69.90398368867204\n"
     ]
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(1000,),activation='logistic',random_state=42)\n",
    "mlp3.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime3 = stop - start\n",
    "print('Runtime: ',runtime3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601513240857504"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69167718, 0.69167718, 0.73076923, 0.69167718, 0.69167718])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp3, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving to a logistic activation function increases the runtime dramatically, but also increases performance. This makes sense at this activation function allows for continuous outputs, thus more accuracy for much more computation resources used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 4: 1 Layer, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  1.7770648221999181\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(100,),random_state=42)\n",
    "mlp4.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime4 = stop - start\n",
    "print('Runtime: ',runtime4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7064312736443884"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7629256 , 0.71941992, 0.6443884 , 0.74842371, 0.78184111])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp4, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, reducing the width of the first layer greater reduced the runtime. Unexpectedly, it also increased the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 5: 3 Layers, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  11.405581517726205\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(1000,100,10),random_state=42)\n",
    "mlp5.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime5 = stop - start\n",
    "print('Runtime: ',runtime5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35182849936948296"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32786885, 0.31021438, 0.69167718, 0.69167718, 0.69041614])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp5, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in extra layers did increase runtime, but not by that much.  Interestingly, it also drastically reduced the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 6: 3 Layers, 100, 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  1.5941980375680487\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp6 = MLPClassifier(hidden_layer_sizes=(100,100,100),random_state=42)\n",
    "mlp6.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime6 = stop - start\n",
    "print('Runtime: ',runtime6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3566204287515763"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp6.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68852459, 0.69546028, 0.69167718, 0.69167718, 0.69041614])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp6, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These configuration has very similar results to the previous one, despite having very different later layouts. This could be because they both have the same amount of neuron connection in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config 7: 7 Layers, 10, 10, 10, 10, 10, 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  1.2823904581418901\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp7 = MLPClassifier(hidden_layer_sizes=(10,10,10,10,10,10,10,),random_state=42)\n",
    "mlp7.fit(Xz, Yz)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "runtime7 = stop - start\n",
    "print('Runtime: ',runtime7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6916771752837326"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp7.score(Xz, Yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69167718, 0.69167718, 0.74842371, 0.69167718, 0.69167718])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp7, Xz, Yz, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration has the lowest runtime, while still having the 3rd highest accuracy, and being very close to the top 2 as well.  Having multiple layers with small groups seems to be a good configuration for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "I found increasing alpha can drastically increae the performance and accuracy of MLP. Additionally, the compuation tradeoff for the logistic activation function is probably too great for the accuracy boost it gives. \n",
    "\n",
    "The number of layers is not anywhere near as important as the total number of neurons, which seems to be much more important when it comes to dictating accuracy and runtime. Also, more neurons does not neccessarily equate to more accuracy. The optimal layer and neuron configuration appears to be very dependent on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
